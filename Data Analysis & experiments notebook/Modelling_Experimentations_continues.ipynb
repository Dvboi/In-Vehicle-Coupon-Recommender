{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelling Experimentations continues.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yoOzM45gTRGE",
        "m9_ZVmr9k6v0",
        "wUuyF0_3tk6N"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Import and loading datasets"
      ],
      "metadata": {
        "id": "yoOzM45gTRGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import defaultdict\n",
        "from joblib import dump, load\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, KFold\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYHxg0K0hKXM",
        "outputId": "ee674deb-5f16-4af9-bfee-0159d2564af0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.4-cp37-none-manylinux1_x86_64.whl (76.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lOADING DIFFERENT ENCODINGS FOR DIFFERENT MODELS\n",
        "\n",
        "train_set1 = pd.read_csv('/content/drive/MyDrive/Datasets/Datasets and utils/train_set1.csv')\n",
        "test_set1 = pd.read_csv('/content/drive/MyDrive/Datasets/Datasets and utils/test_set1.csv')\n",
        "\n",
        "train_set3 = pd.read_csv('/content/drive/MyDrive/Datasets/Datasets and utils/train_set3.csv')\n",
        "test_set3 = pd.read_csv('/content/drive/MyDrive/Datasets/Datasets and utils/test_set3.csv')\n",
        "\n",
        "X_train_cb = pd.read_csv('/content/drive/MyDrive/Datasets/Datasets and utils/X_train_catboost.csv').astype(str)\n",
        "X_test_cb = pd.read_csv('/content/drive/MyDrive/Datasets/Datasets and utils/X_test_catboost.csv').astype(str)\n",
        "\n",
        "y_train = pd.read_csv('/content/drive/MyDrive/Datasets/Datasets and utils/y_train.csv')\n",
        "y_test = pd.read_csv('/content/drive/MyDrive/Datasets/Datasets and utils/y_test.csv')"
      ],
      "metadata": {
        "id": "-3QO6FVKo2pk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stacker"
      ],
      "metadata": {
        "id": "m9_ZVmr9k6v0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's append labels to each training feature-set for stacking purposes\n",
        "train_set1 = pd.concat([train_set1,y_train],axis=1)\n",
        "train_set3 = pd.concat([train_set3,y_train],axis=1)\n",
        "X_train_cb = pd.concat([X_train_cb,y_train],axis=1)\n",
        "\n",
        "\n",
        "class Custom_Stacker:\n",
        "\n",
        "    def __init__(self,k=8):\n",
        "        ''' \n",
        "        Constructor to initialize a few impt variables\n",
        "        Architecture of Stacker :- 8(base_models) + Log-Reg(Meta-model)\n",
        "        All the params taken are the best ones found from previous experimentations\n",
        "        '''\n",
        "        self.k = k\n",
        "        self.best_params = [{'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 50},{'n_neighbors': 25}, {'alpha': 100}, {'C': 0.0001,'dual':False},\n",
        "                            {'n_estimators': 300, 'min_samples_split': 10, 'max_samples': 0.5, 'criterion': 'entropy','random_state':42,'n_jobs' : -1},\n",
        "                            {'C':1,'random_state':42,'kernel':'rbf','probability':True},\n",
        "                            {'subsample': 0.7, 'reg_alpha ': 0.05, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.7,\n",
        "                             'random_state':42,'n_jobs':-1},\n",
        "                            {'min_data_in_leaf': 50, 'depth': 10, 'od_wait': 10, 'l2_leaf_reg': 3, 'iterations': 500, 'subsample': 0.5, 'rsm': 0.3, 'learning_rate': 0.1,\n",
        "                             'loss_function': 'Logloss','random_state':42,'eval_metric':'F1','custom_metric':'F1','one_hot_max_size':3}\n",
        "                            ]\n",
        "        self.base_learners = [DecisionTreeClassifier,KNeighborsClassifier,MultinomialNB,LinearSVC,RandomForestClassifier,SVC,xgboost.XGBClassifier,CatBoostClassifier]\n",
        "        \n",
        "        self.trained_base_learners = []\n",
        "\n",
        "        assert k <= len(self.base_learners),\"No. of base-learners can be maximum {}\".format(len(self.base_learners))\n",
        "\n",
        "    def half_split(self,data):\n",
        "        ''' \n",
        "        To make 50-50 splits of data\n",
        "        '''\n",
        "        d1 = data[:5074]\n",
        "        d2 = data[5074:]\n",
        "        return d1,d2\n",
        "\n",
        "    def fit(self,train_set1,train_set3,X_train_cb):\n",
        "        '''\n",
        "        We have taken 3 feature encoded sets and they are used on their respective models, founded by extensive previous experiments.\n",
        "\n",
        "        1) take 50-50 splits into D1 & D2\n",
        "        2) Train base-learners on D1 (Sample with replacement) and make predictions on D2\n",
        "        3) USE each Base-learner's predictions on D2 with labels as train data for meta-model\n",
        "        4) TRAIN and store your Meta-model and use it for prediction\n",
        "\n",
        "        '''\n",
        "        # 50-50 split train to D1 & D2\n",
        "\n",
        "        train_set1_d1,train_set1_d2 = self.half_split(train_set1)\n",
        "        train_set3_d1,train_set3_d2 = self.half_split(train_set3)\n",
        "        X_train_cb_d1,X_train_cb_d2 = self.half_split(X_train_cb)\n",
        "\n",
        "        \n",
        "        # assigning feature-set for each model, according to our observations from the previous experiments\n",
        "        self.feature_set_d1 = [train_set3_d1,train_set1_d1,train_set1_d1,train_set1_d1,train_set3_d1,train_set1_d1,train_set3_d1,X_train_cb_d1][:self.k]\n",
        "        self.feature_set_d2 = [train_set3_d2,train_set1_d2,train_set1_d2,train_set1_d2,train_set3_d2,train_set1_d2,train_set3_d2,X_train_cb_d2][:self.k]\n",
        "\n",
        "        # sample with replacement from D1 to train base-models\n",
        "        N = X_train_cb_d1.shape[0]\n",
        "        indices_for_BaseModels = []\n",
        "        for _ in range(self.k):\n",
        "            idx = np.random.choice(a=N,size=int(0.7*N),replace=True)\n",
        "            indices_for_BaseModels.append(idx)\n",
        "\n",
        "        ## training base models\n",
        "        if self.trained_base_learners:  # resetting if already trained with the same object before\n",
        "            self.trained_base_learners = []\n",
        "\n",
        "        for idx,(data_indices,train,model,params) in enumerate(zip(indices_for_BaseModels,self.feature_set_d1,self.base_learners,self.best_params)):\n",
        "            y = train.Y.iloc[data_indices].ravel()\n",
        "            X = train.drop(\"Y\",axis=1).iloc[data_indices,:]\n",
        "            if idx==7:   # if it's catboost model we have to send one extra parameter\n",
        "                cat_features = X.columns.values\n",
        "                model = model(cat_features=cat_features,**params)\n",
        "            else:\n",
        "                model = model(**params)\n",
        "            model.fit(X,y)\n",
        "\n",
        "            self.trained_base_learners.append(model)   # storing trained base-learners\n",
        "\n",
        "\n",
        "        # make predictions through each base-learner on D2 and make dataset D3\n",
        "        M = X_train_cb_d2.shape[0]\n",
        "        D3 = np.zeros((M,self.k))\n",
        "        k = 0\n",
        "        for model,test in zip(self.trained_base_learners,self.feature_set_d2):\n",
        "            X = test.drop(\"Y\",axis=1)\n",
        "            D3[:,k] = model.predict(X)\n",
        "            k += 1\n",
        "\n",
        "        # making D3 a df\n",
        "        D3 = np.hstack((D3,X_train_cb_d2.Y.values.reshape(-1,1)))   # appending labels of D2 to prediction of base-models on d2\n",
        "        self.columns = ['Pred_1','Pred_2','Pred_3','Pred_4','Pred_5','Pred_6','Pred_7','Pred_8'][:self.k]\n",
        "        self.columns.extend('Y')\n",
        "        D3 = pd.DataFrame(D3,columns=self.columns) \n",
        "\n",
        "        # TRAIN metamodel on D3\n",
        "        X,y = D3.drop('Y',axis=1),D3.Y.ravel()\n",
        "        self.MetaModel = LogisticRegression(C=0.001).fit(X,y)\n",
        "        return \n",
        "\n",
        "    def predict(self,test_set1,test_set3,X_test_cb):\n",
        "        '''\n",
        "        This function will make predictions on test set for evaluation\n",
        "        1) Predict the values for test set using your base learners\n",
        "        2) Then use the ouputs of those base learners as input to meta-model and make final predictions \n",
        "        '''\n",
        "        # we will pass respective feature-encoded test set to each base-learner\n",
        "        self.feature_set_for_test = [test_set3,test_set1,test_set1,test_set1,test_set3,test_set1,test_set3,X_test_cb][:self.k]\n",
        "\n",
        "        # storing outputs OF Base-learners in D4\n",
        "        N = X_test_cb.shape[0]\n",
        "        D4 = np.zeros((N,self.k))\n",
        "        k = 0\n",
        "        for model,data in zip(self.trained_base_learners,self.feature_set_for_test):\n",
        "            D4[:,k] = model.predict(data)\n",
        "            k += 1\n",
        "\n",
        "        # making D4 a df and using it as input for meta-model and returning it's predictions.\n",
        "        D4 = pd.DataFrame(D4,columns=self.columns[:-1])   # all cols exept 'Y'\n",
        "        return self.MetaModel.predict(D4)\n",
        "\n"
      ],
      "metadata": {
        "id": "HIkKWsD2o2m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's Evaluate"
      ],
      "metadata": {
        "id": "8tD7VhPtlxTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for k in range(8):\n",
        "    clf = Custom_Stacker(k+1)\n",
        "    clf.fit(train_set1,train_set3,X_train_cb)\n",
        "    y_pred = clf.predict(test_set1,test_set3,X_test_cb)\n",
        "    f1 = metrics.f1_score(y_test,y_pred)\n",
        "    results.append(f1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_s0QDd9o2jT",
        "outputId": "15677b99-29f8-4f9e-9d32-7a98fc65c7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.7511737\ttotal: 25.7ms\tremaining: 12.8s\n",
            "1:\tlearn: 0.7946627\ttotal: 53.7ms\tremaining: 13.4s\n",
            "2:\tlearn: 0.8121975\ttotal: 74.5ms\tremaining: 12.3s\n",
            "3:\tlearn: 0.8248971\ttotal: 101ms\tremaining: 12.5s\n",
            "4:\tlearn: 0.8377140\ttotal: 126ms\tremaining: 12.5s\n",
            "5:\tlearn: 0.8502879\ttotal: 147ms\tremaining: 12.1s\n",
            "6:\tlearn: 0.8677249\ttotal: 171ms\tremaining: 12s\n",
            "7:\tlearn: 0.8714869\ttotal: 195ms\tremaining: 12s\n",
            "8:\tlearn: 0.8791156\ttotal: 220ms\tremaining: 12s\n",
            "9:\tlearn: 0.8809410\ttotal: 249ms\tremaining: 12.2s\n",
            "10:\tlearn: 0.8795963\ttotal: 269ms\tremaining: 12s\n",
            "11:\tlearn: 0.8838104\ttotal: 305ms\tremaining: 12.4s\n",
            "12:\tlearn: 0.8864839\ttotal: 329ms\tremaining: 12.3s\n",
            "13:\tlearn: 0.8896337\ttotal: 353ms\tremaining: 12.3s\n",
            "14:\tlearn: 0.8921381\ttotal: 379ms\tremaining: 12.3s\n",
            "15:\tlearn: 0.9035046\ttotal: 401ms\tremaining: 12.1s\n",
            "16:\tlearn: 0.9040173\ttotal: 425ms\tremaining: 12.1s\n",
            "17:\tlearn: 0.9131167\ttotal: 452ms\tremaining: 12.1s\n",
            "18:\tlearn: 0.9190225\ttotal: 481ms\tremaining: 12.2s\n",
            "19:\tlearn: 0.9220437\ttotal: 511ms\tremaining: 12.3s\n",
            "20:\tlearn: 0.9211598\ttotal: 536ms\tremaining: 12.2s\n",
            "21:\tlearn: 0.9217099\ttotal: 562ms\tremaining: 12.2s\n",
            "22:\tlearn: 0.9265482\ttotal: 590ms\tremaining: 12.2s\n",
            "23:\tlearn: 0.9303220\ttotal: 618ms\tremaining: 12.3s\n",
            "24:\tlearn: 0.9309353\ttotal: 647ms\tremaining: 12.3s\n",
            "25:\tlearn: 0.9306788\ttotal: 680ms\tremaining: 12.4s\n",
            "26:\tlearn: 0.9325330\ttotal: 707ms\tremaining: 12.4s\n",
            "27:\tlearn: 0.9331731\ttotal: 734ms\tremaining: 12.4s\n",
            "28:\tlearn: 0.9324357\ttotal: 738ms\tremaining: 12s\n",
            "29:\tlearn: 0.9338147\ttotal: 766ms\tremaining: 12s\n",
            "30:\tlearn: 0.9347145\ttotal: 790ms\tremaining: 11.9s\n",
            "31:\tlearn: 0.9389331\ttotal: 818ms\tremaining: 12s\n",
            "32:\tlearn: 0.9416586\ttotal: 848ms\tremaining: 12s\n",
            "33:\tlearn: 0.9431599\ttotal: 890ms\tremaining: 12.2s\n",
            "34:\tlearn: 0.9452088\ttotal: 915ms\tremaining: 12.2s\n",
            "35:\tlearn: 0.9480802\ttotal: 943ms\tremaining: 12.2s\n",
            "36:\tlearn: 0.9501693\ttotal: 973ms\tremaining: 12.2s\n",
            "37:\tlearn: 0.9516675\ttotal: 1s\tremaining: 12.2s\n",
            "38:\tlearn: 0.9523118\ttotal: 1.03s\tremaining: 12.2s\n",
            "39:\tlearn: 0.9527502\ttotal: 1.06s\tremaining: 12.2s\n",
            "40:\tlearn: 0.9548763\ttotal: 1.08s\tremaining: 12.1s\n",
            "41:\tlearn: 0.9561425\ttotal: 1.12s\tremaining: 12.2s\n",
            "42:\tlearn: 0.9582322\ttotal: 1.15s\tremaining: 12.2s\n",
            "43:\tlearn: 0.9579995\ttotal: 1.18s\tremaining: 12.2s\n",
            "44:\tlearn: 0.9619883\ttotal: 1.21s\tremaining: 12.2s\n",
            "45:\tlearn: 0.9634503\ttotal: 1.23s\tremaining: 12.2s\n",
            "46:\tlearn: 0.9646428\ttotal: 1.26s\tremaining: 12.1s\n",
            "47:\tlearn: 0.9660893\ttotal: 1.29s\tremaining: 12.2s\n",
            "48:\tlearn: 0.9682462\ttotal: 1.32s\tremaining: 12.2s\n",
            "49:\tlearn: 0.9679941\ttotal: 1.35s\tremaining: 12.2s\n",
            "50:\tlearn: 0.9684211\ttotal: 1.38s\tremaining: 12.1s\n",
            "51:\tlearn: 0.9699193\ttotal: 1.4s\tremaining: 12.1s\n",
            "52:\tlearn: 0.9715826\ttotal: 1.43s\tremaining: 12.1s\n",
            "53:\tlearn: 0.9718206\ttotal: 1.46s\tremaining: 12s\n",
            "54:\tlearn: 0.9732647\ttotal: 1.48s\tremaining: 12s\n",
            "55:\tlearn: 0.9752026\ttotal: 1.51s\tremaining: 12s\n",
            "56:\tlearn: 0.9742205\ttotal: 1.54s\tremaining: 11.9s\n",
            "57:\tlearn: 0.9749632\ttotal: 1.57s\tremaining: 11.9s\n",
            "58:\tlearn: 0.9747239\ttotal: 1.59s\tremaining: 11.9s\n",
            "59:\tlearn: 0.9751904\ttotal: 1.62s\tremaining: 11.9s\n",
            "60:\tlearn: 0.9759214\ttotal: 1.65s\tremaining: 11.9s\n",
            "61:\tlearn: 0.9776248\ttotal: 1.68s\tremaining: 11.9s\n",
            "62:\tlearn: 0.9788490\ttotal: 1.71s\tremaining: 11.9s\n",
            "63:\tlearn: 0.9815225\ttotal: 1.75s\tremaining: 11.9s\n",
            "64:\tlearn: 0.9820064\ttotal: 1.77s\tremaining: 11.8s\n",
            "65:\tlearn: 0.9817644\ttotal: 1.8s\tremaining: 11.8s\n",
            "66:\tlearn: 0.9817644\ttotal: 1.8s\tremaining: 11.6s\n",
            "67:\tlearn: 0.9822660\ttotal: 1.83s\tremaining: 11.6s\n",
            "68:\tlearn: 0.9822660\ttotal: 1.86s\tremaining: 11.6s\n",
            "69:\tlearn: 0.9830007\ttotal: 1.88s\tremaining: 11.6s\n",
            "70:\tlearn: 0.9834772\ttotal: 1.91s\tremaining: 11.5s\n",
            "71:\tlearn: 0.9839625\ttotal: 1.93s\tremaining: 11.5s\n",
            "72:\tlearn: 0.9856719\ttotal: 1.96s\tremaining: 11.5s\n",
            "73:\tlearn: 0.9868909\ttotal: 1.99s\tremaining: 11.5s\n",
            "74:\tlearn: 0.9868909\ttotal: 1.99s\tremaining: 11.3s\n",
            "75:\tlearn: 0.9873981\ttotal: 2.01s\tremaining: 11.2s\n",
            "76:\tlearn: 0.9878923\ttotal: 2.04s\tremaining: 11.2s\n",
            "77:\tlearn: 0.9881247\ttotal: 2.06s\tremaining: 11.2s\n",
            "78:\tlearn: 0.9881306\ttotal: 2.09s\tremaining: 11.2s\n",
            "79:\tlearn: 0.9881247\ttotal: 2.12s\tremaining: 11.1s\n",
            "80:\tlearn: 0.9883750\ttotal: 2.14s\tremaining: 11.1s\n",
            "81:\tlearn: 0.9881306\ttotal: 2.17s\tremaining: 11.1s\n",
            "82:\tlearn: 0.9888752\ttotal: 2.2s\tremaining: 11s\n",
            "83:\tlearn: 0.9896091\ttotal: 2.23s\tremaining: 11s\n",
            "84:\tlearn: 0.9893643\ttotal: 2.26s\tremaining: 11s\n",
            "85:\tlearn: 0.9901137\ttotal: 2.29s\tremaining: 11s\n",
            "86:\tlearn: 0.9908574\ttotal: 2.33s\tremaining: 11.1s\n",
            "87:\tlearn: 0.9906126\ttotal: 2.36s\tremaining: 11.1s\n",
            "88:\tlearn: 0.9906126\ttotal: 2.39s\tremaining: 11s\n",
            "89:\tlearn: 0.9918418\ttotal: 2.42s\tremaining: 11s\n",
            "90:\tlearn: 0.9920870\ttotal: 2.45s\tremaining: 11s\n",
            "91:\tlearn: 0.9913473\ttotal: 2.48s\tremaining: 11s\n",
            "92:\tlearn: 0.9918418\ttotal: 2.5s\tremaining: 11s\n",
            "93:\tlearn: 0.9923362\ttotal: 2.53s\tremaining: 10.9s\n",
            "94:\tlearn: 0.9928307\ttotal: 2.56s\tremaining: 10.9s\n",
            "95:\tlearn: 0.9930762\ttotal: 2.6s\tremaining: 10.9s\n",
            "96:\tlearn: 0.9935739\ttotal: 2.63s\tremaining: 10.9s\n",
            "97:\tlearn: 0.9938195\ttotal: 2.65s\tremaining: 10.9s\n",
            "98:\tlearn: 0.9935739\ttotal: 2.68s\tremaining: 10.8s\n",
            "99:\tlearn: 0.9935739\ttotal: 2.71s\tremaining: 10.8s\n",
            "100:\tlearn: 0.9938195\ttotal: 2.74s\tremaining: 10.8s\n",
            "101:\tlearn: 0.9935707\ttotal: 2.76s\tremaining: 10.8s\n",
            "102:\tlearn: 0.9940653\ttotal: 2.79s\tremaining: 10.7s\n",
            "103:\tlearn: 0.9950520\ttotal: 2.82s\tremaining: 10.7s\n",
            "104:\tlearn: 0.9950520\ttotal: 2.84s\tremaining: 10.7s\n",
            "105:\tlearn: 0.9945598\ttotal: 2.87s\tremaining: 10.7s\n",
            "106:\tlearn: 0.9948058\ttotal: 2.9s\tremaining: 10.6s\n",
            "107:\tlearn: 0.9950520\ttotal: 2.92s\tremaining: 10.6s\n",
            "108:\tlearn: 0.9950520\ttotal: 2.95s\tremaining: 10.6s\n",
            "109:\tlearn: 0.9960376\ttotal: 2.97s\tremaining: 10.5s\n",
            "110:\tlearn: 0.9962844\ttotal: 3.01s\tremaining: 10.6s\n",
            "111:\tlearn: 0.9970268\ttotal: 3.04s\tremaining: 10.5s\n",
            "112:\tlearn: 0.9965329\ttotal: 3.07s\tremaining: 10.5s\n",
            "113:\tlearn: 0.9967798\ttotal: 3.09s\tremaining: 10.5s\n",
            "114:\tlearn: 0.9962844\ttotal: 3.12s\tremaining: 10.4s\n",
            "115:\tlearn: 0.9962844\ttotal: 3.15s\tremaining: 10.4s\n",
            "116:\tlearn: 0.9970268\ttotal: 3.18s\tremaining: 10.4s\n",
            "117:\tlearn: 0.9977717\ttotal: 3.21s\tremaining: 10.4s\n",
            "118:\tlearn: 0.9980188\ttotal: 3.23s\tremaining: 10.4s\n",
            "119:\tlearn: 0.9982678\ttotal: 3.26s\tremaining: 10.3s\n",
            "120:\tlearn: 0.9985149\ttotal: 3.29s\tremaining: 10.3s\n",
            "121:\tlearn: 0.9982678\ttotal: 3.32s\tremaining: 10.3s\n",
            "122:\tlearn: 0.9982678\ttotal: 3.35s\tremaining: 10.3s\n",
            "123:\tlearn: 0.9985149\ttotal: 3.38s\tremaining: 10.3s\n",
            "124:\tlearn: 0.9987621\ttotal: 3.41s\tremaining: 10.2s\n",
            "125:\tlearn: 0.9987621\ttotal: 3.43s\tremaining: 10.2s\n",
            "126:\tlearn: 0.9987621\ttotal: 3.46s\tremaining: 10.2s\n",
            "127:\tlearn: 0.9987621\ttotal: 3.49s\tremaining: 10.2s\n",
            "128:\tlearn: 0.9990094\ttotal: 3.52s\tremaining: 10.1s\n",
            "129:\tlearn: 0.9990094\ttotal: 3.54s\tremaining: 10.1s\n",
            "130:\tlearn: 0.9990094\ttotal: 3.57s\tremaining: 10.1s\n",
            "131:\tlearn: 0.9990094\ttotal: 3.6s\tremaining: 10s\n",
            "132:\tlearn: 0.9992569\ttotal: 3.63s\tremaining: 10s\n",
            "133:\tlearn: 0.9992569\ttotal: 3.65s\tremaining: 9.96s\n",
            "134:\tlearn: 0.9992569\ttotal: 3.67s\tremaining: 9.93s\n",
            "135:\tlearn: 0.9992569\ttotal: 3.7s\tremaining: 9.9s\n",
            "136:\tlearn: 0.9992569\ttotal: 3.72s\tremaining: 9.87s\n",
            "137:\tlearn: 0.9992569\ttotal: 3.75s\tremaining: 9.83s\n",
            "138:\tlearn: 0.9992569\ttotal: 3.78s\tremaining: 9.81s\n",
            "139:\tlearn: 0.9992569\ttotal: 3.8s\tremaining: 9.78s\n",
            "140:\tlearn: 0.9992569\ttotal: 3.83s\tremaining: 9.74s\n",
            "141:\tlearn: 0.9992569\ttotal: 3.85s\tremaining: 9.72s\n",
            "142:\tlearn: 0.9992569\ttotal: 3.88s\tremaining: 9.68s\n",
            "143:\tlearn: 0.9992569\ttotal: 3.9s\tremaining: 9.65s\n",
            "144:\tlearn: 0.9992569\ttotal: 3.93s\tremaining: 9.63s\n",
            "145:\tlearn: 0.9992569\ttotal: 3.97s\tremaining: 9.62s\n",
            "146:\tlearn: 0.9992569\ttotal: 3.99s\tremaining: 9.59s\n",
            "147:\tlearn: 0.9992569\ttotal: 4.02s\tremaining: 9.56s\n",
            "148:\tlearn: 0.9992569\ttotal: 4.04s\tremaining: 9.52s\n",
            "149:\tlearn: 0.9995047\ttotal: 4.07s\tremaining: 9.49s\n",
            "150:\tlearn: 0.9992569\ttotal: 4.09s\tremaining: 9.46s\n",
            "151:\tlearn: 0.9995047\ttotal: 4.12s\tremaining: 9.43s\n",
            "152:\tlearn: 0.9995047\ttotal: 4.15s\tremaining: 9.4s\n",
            "153:\tlearn: 0.9995047\ttotal: 4.18s\tremaining: 9.39s\n",
            "154:\tlearn: 0.9995047\ttotal: 4.21s\tremaining: 9.36s\n",
            "155:\tlearn: 0.9995047\ttotal: 4.23s\tremaining: 9.33s\n",
            "156:\tlearn: 0.9995047\ttotal: 4.26s\tremaining: 9.31s\n",
            "157:\tlearn: 0.9995047\ttotal: 4.29s\tremaining: 9.28s\n",
            "158:\tlearn: 0.9995047\ttotal: 4.33s\tremaining: 9.29s\n",
            "159:\tlearn: 0.9995047\ttotal: 4.35s\tremaining: 9.25s\n",
            "160:\tlearn: 0.9995047\ttotal: 4.38s\tremaining: 9.23s\n",
            "161:\tlearn: 0.9997523\ttotal: 4.41s\tremaining: 9.2s\n",
            "162:\tlearn: 0.9997523\ttotal: 4.44s\tremaining: 9.18s\n",
            "163:\tlearn: 0.9997523\ttotal: 4.47s\tremaining: 9.15s\n",
            "164:\tlearn: 0.9997523\ttotal: 4.49s\tremaining: 9.12s\n",
            "165:\tlearn: 0.9997523\ttotal: 4.52s\tremaining: 9.1s\n",
            "166:\tlearn: 0.9997523\ttotal: 4.56s\tremaining: 9.09s\n",
            "167:\tlearn: 0.9997523\ttotal: 4.59s\tremaining: 9.06s\n",
            "168:\tlearn: 0.9997523\ttotal: 4.61s\tremaining: 9.04s\n",
            "169:\tlearn: 0.9997523\ttotal: 4.64s\tremaining: 9.01s\n",
            "170:\tlearn: 0.9997523\ttotal: 4.67s\tremaining: 8.99s\n",
            "171:\tlearn: 0.9997523\ttotal: 4.7s\tremaining: 8.97s\n",
            "172:\tlearn: 0.9997523\ttotal: 4.73s\tremaining: 8.94s\n",
            "173:\tlearn: 0.9997523\ttotal: 4.76s\tremaining: 8.91s\n",
            "174:\tlearn: 0.9997523\ttotal: 4.79s\tremaining: 8.89s\n",
            "175:\tlearn: 0.9997523\ttotal: 4.81s\tremaining: 8.86s\n",
            "176:\tlearn: 0.9997523\ttotal: 4.84s\tremaining: 8.83s\n",
            "177:\tlearn: 0.9997523\ttotal: 4.87s\tremaining: 8.8s\n",
            "178:\tlearn: 0.9997523\ttotal: 4.89s\tremaining: 8.77s\n",
            "179:\tlearn: 0.9997523\ttotal: 4.92s\tremaining: 8.74s\n",
            "180:\tlearn: 0.9997523\ttotal: 4.95s\tremaining: 8.72s\n",
            "181:\tlearn: 0.9997523\ttotal: 4.98s\tremaining: 8.71s\n",
            "182:\tlearn: 0.9997523\ttotal: 5.01s\tremaining: 8.68s\n",
            "183:\tlearn: 0.9997523\ttotal: 5.04s\tremaining: 8.65s\n",
            "184:\tlearn: 0.9997523\ttotal: 5.06s\tremaining: 8.62s\n",
            "185:\tlearn: 0.9997523\ttotal: 5.09s\tremaining: 8.59s\n",
            "186:\tlearn: 0.9997523\ttotal: 5.12s\tremaining: 8.57s\n",
            "187:\tlearn: 0.9997523\ttotal: 5.14s\tremaining: 8.54s\n",
            "188:\tlearn: 0.9997523\ttotal: 5.17s\tremaining: 8.51s\n",
            "189:\tlearn: 0.9997523\ttotal: 5.2s\tremaining: 8.48s\n",
            "190:\tlearn: 0.9997523\ttotal: 5.23s\tremaining: 8.47s\n",
            "191:\tlearn: 0.9997523\ttotal: 5.26s\tremaining: 8.44s\n",
            "192:\tlearn: 0.9997523\ttotal: 5.29s\tremaining: 8.42s\n",
            "193:\tlearn: 0.9997523\ttotal: 5.33s\tremaining: 8.41s\n",
            "194:\tlearn: 0.9997523\ttotal: 5.35s\tremaining: 8.37s\n",
            "195:\tlearn: 0.9997523\ttotal: 5.38s\tremaining: 8.34s\n",
            "196:\tlearn: 0.9997523\ttotal: 5.41s\tremaining: 8.31s\n",
            "197:\tlearn: 0.9997523\ttotal: 5.43s\tremaining: 8.29s\n",
            "198:\tlearn: 0.9997523\ttotal: 5.46s\tremaining: 8.25s\n",
            "199:\tlearn: 0.9997523\ttotal: 5.49s\tremaining: 8.23s\n",
            "200:\tlearn: 0.9997523\ttotal: 5.51s\tremaining: 8.2s\n",
            "201:\tlearn: 0.9997523\ttotal: 5.54s\tremaining: 8.17s\n",
            "202:\tlearn: 0.9997523\ttotal: 5.57s\tremaining: 8.15s\n",
            "203:\tlearn: 0.9997523\ttotal: 5.59s\tremaining: 8.12s\n",
            "204:\tlearn: 0.9997523\ttotal: 5.63s\tremaining: 8.1s\n",
            "205:\tlearn: 1.0000000\ttotal: 5.65s\tremaining: 8.06s\n",
            "206:\tlearn: 0.9997523\ttotal: 5.68s\tremaining: 8.04s\n",
            "207:\tlearn: 1.0000000\ttotal: 5.7s\tremaining: 8.01s\n",
            "208:\tlearn: 1.0000000\ttotal: 5.74s\tremaining: 7.99s\n",
            "209:\tlearn: 1.0000000\ttotal: 5.76s\tremaining: 7.95s\n",
            "210:\tlearn: 1.0000000\ttotal: 5.79s\tremaining: 7.93s\n",
            "211:\tlearn: 1.0000000\ttotal: 5.82s\tremaining: 7.9s\n",
            "212:\tlearn: 0.9997523\ttotal: 5.85s\tremaining: 7.88s\n",
            "213:\tlearn: 0.9997523\ttotal: 5.87s\tremaining: 7.85s\n",
            "214:\tlearn: 1.0000000\ttotal: 5.9s\tremaining: 7.82s\n",
            "215:\tlearn: 1.0000000\ttotal: 5.92s\tremaining: 7.79s\n",
            "216:\tlearn: 1.0000000\ttotal: 5.95s\tremaining: 7.76s\n",
            "217:\tlearn: 1.0000000\ttotal: 5.98s\tremaining: 7.73s\n",
            "218:\tlearn: 1.0000000\ttotal: 6s\tremaining: 7.7s\n",
            "219:\tlearn: 1.0000000\ttotal: 6.03s\tremaining: 7.67s\n",
            "220:\tlearn: 1.0000000\ttotal: 6.06s\tremaining: 7.65s\n",
            "221:\tlearn: 1.0000000\ttotal: 6.09s\tremaining: 7.62s\n",
            "222:\tlearn: 1.0000000\ttotal: 6.12s\tremaining: 7.6s\n",
            "223:\tlearn: 1.0000000\ttotal: 6.15s\tremaining: 7.58s\n",
            "224:\tlearn: 1.0000000\ttotal: 6.18s\tremaining: 7.55s\n",
            "225:\tlearn: 1.0000000\ttotal: 6.21s\tremaining: 7.53s\n",
            "226:\tlearn: 1.0000000\ttotal: 6.23s\tremaining: 7.5s\n",
            "227:\tlearn: 1.0000000\ttotal: 6.26s\tremaining: 7.47s\n",
            "228:\tlearn: 1.0000000\ttotal: 6.29s\tremaining: 7.45s\n",
            "229:\tlearn: 1.0000000\ttotal: 6.32s\tremaining: 7.42s\n",
            "230:\tlearn: 1.0000000\ttotal: 6.36s\tremaining: 7.4s\n",
            "231:\tlearn: 1.0000000\ttotal: 6.39s\tremaining: 7.38s\n",
            "232:\tlearn: 1.0000000\ttotal: 6.41s\tremaining: 7.35s\n",
            "233:\tlearn: 1.0000000\ttotal: 6.44s\tremaining: 7.32s\n",
            "234:\tlearn: 1.0000000\ttotal: 6.47s\tremaining: 7.3s\n",
            "235:\tlearn: 1.0000000\ttotal: 6.5s\tremaining: 7.27s\n",
            "236:\tlearn: 1.0000000\ttotal: 6.52s\tremaining: 7.24s\n",
            "237:\tlearn: 1.0000000\ttotal: 6.55s\tremaining: 7.21s\n",
            "238:\tlearn: 1.0000000\ttotal: 6.58s\tremaining: 7.18s\n",
            "239:\tlearn: 1.0000000\ttotal: 6.61s\tremaining: 7.16s\n",
            "240:\tlearn: 1.0000000\ttotal: 6.64s\tremaining: 7.13s\n",
            "241:\tlearn: 1.0000000\ttotal: 6.66s\tremaining: 7.11s\n",
            "242:\tlearn: 1.0000000\ttotal: 6.7s\tremaining: 7.08s\n",
            "243:\tlearn: 1.0000000\ttotal: 6.73s\tremaining: 7.06s\n",
            "244:\tlearn: 1.0000000\ttotal: 6.75s\tremaining: 7.03s\n",
            "245:\tlearn: 1.0000000\ttotal: 6.78s\tremaining: 7s\n",
            "246:\tlearn: 1.0000000\ttotal: 6.81s\tremaining: 6.97s\n",
            "247:\tlearn: 1.0000000\ttotal: 6.84s\tremaining: 6.95s\n",
            "248:\tlearn: 1.0000000\ttotal: 6.87s\tremaining: 6.92s\n",
            "249:\tlearn: 1.0000000\ttotal: 6.89s\tremaining: 6.89s\n",
            "250:\tlearn: 1.0000000\ttotal: 6.93s\tremaining: 6.87s\n",
            "251:\tlearn: 1.0000000\ttotal: 6.95s\tremaining: 6.84s\n",
            "252:\tlearn: 1.0000000\ttotal: 6.98s\tremaining: 6.81s\n",
            "253:\tlearn: 1.0000000\ttotal: 7.01s\tremaining: 6.79s\n",
            "254:\tlearn: 1.0000000\ttotal: 7.03s\tremaining: 6.75s\n",
            "255:\tlearn: 1.0000000\ttotal: 7.06s\tremaining: 6.72s\n",
            "256:\tlearn: 1.0000000\ttotal: 7.08s\tremaining: 6.7s\n",
            "257:\tlearn: 1.0000000\ttotal: 7.11s\tremaining: 6.67s\n",
            "258:\tlearn: 1.0000000\ttotal: 7.14s\tremaining: 6.64s\n",
            "259:\tlearn: 1.0000000\ttotal: 7.16s\tremaining: 6.61s\n",
            "260:\tlearn: 1.0000000\ttotal: 7.18s\tremaining: 6.58s\n",
            "261:\tlearn: 1.0000000\ttotal: 7.21s\tremaining: 6.55s\n",
            "262:\tlearn: 1.0000000\ttotal: 7.23s\tremaining: 6.52s\n",
            "263:\tlearn: 1.0000000\ttotal: 7.26s\tremaining: 6.49s\n",
            "264:\tlearn: 1.0000000\ttotal: 7.28s\tremaining: 6.46s\n",
            "265:\tlearn: 1.0000000\ttotal: 7.31s\tremaining: 6.43s\n",
            "266:\tlearn: 1.0000000\ttotal: 7.38s\tremaining: 6.44s\n",
            "267:\tlearn: 1.0000000\ttotal: 7.4s\tremaining: 6.41s\n",
            "268:\tlearn: 1.0000000\ttotal: 7.42s\tremaining: 6.37s\n",
            "269:\tlearn: 1.0000000\ttotal: 7.45s\tremaining: 6.35s\n",
            "270:\tlearn: 1.0000000\ttotal: 7.47s\tremaining: 6.32s\n",
            "271:\tlearn: 1.0000000\ttotal: 7.5s\tremaining: 6.29s\n",
            "272:\tlearn: 1.0000000\ttotal: 7.53s\tremaining: 6.26s\n",
            "273:\tlearn: 1.0000000\ttotal: 7.56s\tremaining: 6.23s\n",
            "274:\tlearn: 1.0000000\ttotal: 7.6s\tremaining: 6.21s\n",
            "275:\tlearn: 1.0000000\ttotal: 7.62s\tremaining: 6.18s\n",
            "276:\tlearn: 1.0000000\ttotal: 7.64s\tremaining: 6.15s\n",
            "277:\tlearn: 1.0000000\ttotal: 7.67s\tremaining: 6.13s\n",
            "278:\tlearn: 1.0000000\ttotal: 7.7s\tremaining: 6.1s\n",
            "279:\tlearn: 1.0000000\ttotal: 7.73s\tremaining: 6.07s\n",
            "280:\tlearn: 1.0000000\ttotal: 7.75s\tremaining: 6.04s\n",
            "281:\tlearn: 1.0000000\ttotal: 7.78s\tremaining: 6.02s\n",
            "282:\tlearn: 1.0000000\ttotal: 7.81s\tremaining: 5.99s\n",
            "283:\tlearn: 1.0000000\ttotal: 7.84s\tremaining: 5.96s\n",
            "284:\tlearn: 1.0000000\ttotal: 7.87s\tremaining: 5.93s\n",
            "285:\tlearn: 1.0000000\ttotal: 7.89s\tremaining: 5.91s\n",
            "286:\tlearn: 1.0000000\ttotal: 7.92s\tremaining: 5.88s\n",
            "287:\tlearn: 1.0000000\ttotal: 7.95s\tremaining: 5.85s\n",
            "288:\tlearn: 1.0000000\ttotal: 7.98s\tremaining: 5.82s\n",
            "289:\tlearn: 1.0000000\ttotal: 8s\tremaining: 5.79s\n",
            "290:\tlearn: 1.0000000\ttotal: 8.03s\tremaining: 5.77s\n",
            "291:\tlearn: 1.0000000\ttotal: 8.06s\tremaining: 5.74s\n",
            "292:\tlearn: 1.0000000\ttotal: 8.08s\tremaining: 5.71s\n",
            "293:\tlearn: 1.0000000\ttotal: 8.11s\tremaining: 5.68s\n",
            "294:\tlearn: 1.0000000\ttotal: 8.14s\tremaining: 5.65s\n",
            "295:\tlearn: 1.0000000\ttotal: 8.16s\tremaining: 5.63s\n",
            "296:\tlearn: 1.0000000\ttotal: 8.19s\tremaining: 5.6s\n",
            "297:\tlearn: 1.0000000\ttotal: 8.24s\tremaining: 5.59s\n",
            "298:\tlearn: 1.0000000\ttotal: 8.29s\tremaining: 5.57s\n",
            "299:\tlearn: 1.0000000\ttotal: 8.32s\tremaining: 5.55s\n",
            "300:\tlearn: 1.0000000\ttotal: 8.38s\tremaining: 5.54s\n",
            "301:\tlearn: 1.0000000\ttotal: 8.43s\tremaining: 5.53s\n",
            "302:\tlearn: 1.0000000\ttotal: 8.49s\tremaining: 5.52s\n",
            "303:\tlearn: 1.0000000\ttotal: 8.55s\tremaining: 5.51s\n",
            "304:\tlearn: 1.0000000\ttotal: 8.61s\tremaining: 5.5s\n",
            "305:\tlearn: 1.0000000\ttotal: 8.67s\tremaining: 5.5s\n",
            "306:\tlearn: 1.0000000\ttotal: 8.72s\tremaining: 5.48s\n",
            "307:\tlearn: 1.0000000\ttotal: 8.76s\tremaining: 5.46s\n",
            "308:\tlearn: 1.0000000\ttotal: 8.81s\tremaining: 5.44s\n",
            "309:\tlearn: 1.0000000\ttotal: 8.87s\tremaining: 5.43s\n",
            "310:\tlearn: 1.0000000\ttotal: 8.91s\tremaining: 5.41s\n",
            "311:\tlearn: 1.0000000\ttotal: 8.97s\tremaining: 5.41s\n",
            "312:\tlearn: 1.0000000\ttotal: 9.03s\tremaining: 5.39s\n",
            "313:\tlearn: 1.0000000\ttotal: 9.09s\tremaining: 5.38s\n",
            "314:\tlearn: 1.0000000\ttotal: 9.16s\tremaining: 5.38s\n",
            "315:\tlearn: 1.0000000\ttotal: 9.22s\tremaining: 5.37s\n",
            "316:\tlearn: 1.0000000\ttotal: 9.28s\tremaining: 5.35s\n",
            "317:\tlearn: 1.0000000\ttotal: 9.32s\tremaining: 5.33s\n",
            "318:\tlearn: 1.0000000\ttotal: 9.39s\tremaining: 5.33s\n",
            "319:\tlearn: 1.0000000\ttotal: 9.44s\tremaining: 5.31s\n",
            "320:\tlearn: 1.0000000\ttotal: 9.5s\tremaining: 5.3s\n",
            "321:\tlearn: 1.0000000\ttotal: 9.56s\tremaining: 5.28s\n",
            "322:\tlearn: 1.0000000\ttotal: 9.62s\tremaining: 5.27s\n",
            "323:\tlearn: 1.0000000\ttotal: 9.67s\tremaining: 5.25s\n",
            "324:\tlearn: 1.0000000\ttotal: 9.73s\tremaining: 5.24s\n",
            "325:\tlearn: 1.0000000\ttotal: 9.78s\tremaining: 5.22s\n",
            "326:\tlearn: 1.0000000\ttotal: 9.84s\tremaining: 5.2s\n",
            "327:\tlearn: 1.0000000\ttotal: 9.87s\tremaining: 5.18s\n",
            "328:\tlearn: 1.0000000\ttotal: 9.91s\tremaining: 5.15s\n",
            "329:\tlearn: 1.0000000\ttotal: 9.95s\tremaining: 5.13s\n",
            "330:\tlearn: 1.0000000\ttotal: 10s\tremaining: 5.11s\n",
            "331:\tlearn: 1.0000000\ttotal: 10.1s\tremaining: 5.09s\n",
            "332:\tlearn: 1.0000000\ttotal: 10.1s\tremaining: 5.08s\n",
            "333:\tlearn: 1.0000000\ttotal: 10.2s\tremaining: 5.07s\n",
            "334:\tlearn: 1.0000000\ttotal: 10.3s\tremaining: 5.05s\n",
            "335:\tlearn: 1.0000000\ttotal: 10.3s\tremaining: 5.03s\n",
            "336:\tlearn: 1.0000000\ttotal: 10.4s\tremaining: 5.01s\n",
            "337:\tlearn: 1.0000000\ttotal: 10.4s\tremaining: 4.99s\n",
            "338:\tlearn: 1.0000000\ttotal: 10.5s\tremaining: 4.97s\n",
            "339:\tlearn: 1.0000000\ttotal: 10.5s\tremaining: 4.95s\n",
            "340:\tlearn: 1.0000000\ttotal: 10.6s\tremaining: 4.94s\n",
            "341:\tlearn: 1.0000000\ttotal: 10.6s\tremaining: 4.91s\n",
            "342:\tlearn: 1.0000000\ttotal: 10.6s\tremaining: 4.87s\n",
            "343:\tlearn: 1.0000000\ttotal: 10.7s\tremaining: 4.84s\n",
            "344:\tlearn: 1.0000000\ttotal: 10.7s\tremaining: 4.81s\n",
            "345:\tlearn: 1.0000000\ttotal: 10.7s\tremaining: 4.77s\n",
            "346:\tlearn: 1.0000000\ttotal: 10.8s\tremaining: 4.74s\n",
            "347:\tlearn: 1.0000000\ttotal: 10.8s\tremaining: 4.71s\n",
            "348:\tlearn: 1.0000000\ttotal: 10.8s\tremaining: 4.68s\n",
            "349:\tlearn: 1.0000000\ttotal: 10.8s\tremaining: 4.65s\n",
            "350:\tlearn: 1.0000000\ttotal: 10.9s\tremaining: 4.62s\n",
            "351:\tlearn: 1.0000000\ttotal: 10.9s\tremaining: 4.58s\n",
            "352:\tlearn: 1.0000000\ttotal: 10.9s\tremaining: 4.55s\n",
            "353:\tlearn: 1.0000000\ttotal: 11s\tremaining: 4.52s\n",
            "354:\tlearn: 1.0000000\ttotal: 11s\tremaining: 4.48s\n",
            "355:\tlearn: 1.0000000\ttotal: 11s\tremaining: 4.45s\n",
            "356:\tlearn: 1.0000000\ttotal: 11s\tremaining: 4.42s\n",
            "357:\tlearn: 1.0000000\ttotal: 11.1s\tremaining: 4.39s\n",
            "358:\tlearn: 1.0000000\ttotal: 11.1s\tremaining: 4.36s\n",
            "359:\tlearn: 1.0000000\ttotal: 11.1s\tremaining: 4.32s\n",
            "360:\tlearn: 1.0000000\ttotal: 11.1s\tremaining: 4.29s\n",
            "361:\tlearn: 1.0000000\ttotal: 11.2s\tremaining: 4.26s\n",
            "362:\tlearn: 1.0000000\ttotal: 11.2s\tremaining: 4.23s\n",
            "363:\tlearn: 1.0000000\ttotal: 11.2s\tremaining: 4.2s\n",
            "364:\tlearn: 1.0000000\ttotal: 11.3s\tremaining: 4.17s\n",
            "365:\tlearn: 1.0000000\ttotal: 11.3s\tremaining: 4.14s\n",
            "366:\tlearn: 1.0000000\ttotal: 11.3s\tremaining: 4.1s\n",
            "367:\tlearn: 1.0000000\ttotal: 11.4s\tremaining: 4.07s\n",
            "368:\tlearn: 1.0000000\ttotal: 11.4s\tremaining: 4.04s\n",
            "369:\tlearn: 1.0000000\ttotal: 11.4s\tremaining: 4.01s\n",
            "370:\tlearn: 1.0000000\ttotal: 11.4s\tremaining: 3.98s\n",
            "371:\tlearn: 1.0000000\ttotal: 11.5s\tremaining: 3.95s\n",
            "372:\tlearn: 1.0000000\ttotal: 11.5s\tremaining: 3.92s\n",
            "373:\tlearn: 1.0000000\ttotal: 11.5s\tremaining: 3.88s\n",
            "374:\tlearn: 1.0000000\ttotal: 11.6s\tremaining: 3.85s\n",
            "375:\tlearn: 1.0000000\ttotal: 11.6s\tremaining: 3.82s\n",
            "376:\tlearn: 1.0000000\ttotal: 11.6s\tremaining: 3.79s\n",
            "377:\tlearn: 1.0000000\ttotal: 11.6s\tremaining: 3.76s\n",
            "378:\tlearn: 1.0000000\ttotal: 11.7s\tremaining: 3.73s\n",
            "379:\tlearn: 1.0000000\ttotal: 11.7s\tremaining: 3.69s\n",
            "380:\tlearn: 1.0000000\ttotal: 11.7s\tremaining: 3.66s\n",
            "381:\tlearn: 1.0000000\ttotal: 11.8s\tremaining: 3.63s\n",
            "382:\tlearn: 1.0000000\ttotal: 11.8s\tremaining: 3.6s\n",
            "383:\tlearn: 1.0000000\ttotal: 11.8s\tremaining: 3.57s\n",
            "384:\tlearn: 1.0000000\ttotal: 11.8s\tremaining: 3.54s\n",
            "385:\tlearn: 1.0000000\ttotal: 11.9s\tremaining: 3.51s\n",
            "386:\tlearn: 1.0000000\ttotal: 11.9s\tremaining: 3.47s\n",
            "387:\tlearn: 1.0000000\ttotal: 11.9s\tremaining: 3.44s\n",
            "388:\tlearn: 1.0000000\ttotal: 12s\tremaining: 3.41s\n",
            "389:\tlearn: 1.0000000\ttotal: 12s\tremaining: 3.38s\n",
            "390:\tlearn: 1.0000000\ttotal: 12s\tremaining: 3.35s\n",
            "391:\tlearn: 1.0000000\ttotal: 12s\tremaining: 3.32s\n",
            "392:\tlearn: 1.0000000\ttotal: 12.1s\tremaining: 3.28s\n",
            "393:\tlearn: 1.0000000\ttotal: 12.1s\tremaining: 3.25s\n",
            "394:\tlearn: 1.0000000\ttotal: 12.1s\tremaining: 3.22s\n",
            "395:\tlearn: 1.0000000\ttotal: 12.1s\tremaining: 3.19s\n",
            "396:\tlearn: 1.0000000\ttotal: 12.2s\tremaining: 3.16s\n",
            "397:\tlearn: 1.0000000\ttotal: 12.2s\tremaining: 3.13s\n",
            "398:\tlearn: 1.0000000\ttotal: 12.2s\tremaining: 3.09s\n",
            "399:\tlearn: 1.0000000\ttotal: 12.3s\tremaining: 3.06s\n",
            "400:\tlearn: 1.0000000\ttotal: 12.3s\tremaining: 3.03s\n",
            "401:\tlearn: 1.0000000\ttotal: 12.3s\tremaining: 3s\n",
            "402:\tlearn: 1.0000000\ttotal: 12.3s\tremaining: 2.97s\n",
            "403:\tlearn: 1.0000000\ttotal: 12.4s\tremaining: 2.94s\n",
            "404:\tlearn: 1.0000000\ttotal: 12.4s\tremaining: 2.91s\n",
            "405:\tlearn: 1.0000000\ttotal: 12.4s\tremaining: 2.88s\n",
            "406:\tlearn: 1.0000000\ttotal: 12.5s\tremaining: 2.85s\n",
            "407:\tlearn: 1.0000000\ttotal: 12.5s\tremaining: 2.82s\n",
            "408:\tlearn: 1.0000000\ttotal: 12.5s\tremaining: 2.79s\n",
            "409:\tlearn: 1.0000000\ttotal: 12.6s\tremaining: 2.75s\n",
            "410:\tlearn: 1.0000000\ttotal: 12.6s\tremaining: 2.72s\n",
            "411:\tlearn: 1.0000000\ttotal: 12.6s\tremaining: 2.69s\n",
            "412:\tlearn: 1.0000000\ttotal: 12.6s\tremaining: 2.66s\n",
            "413:\tlearn: 1.0000000\ttotal: 12.7s\tremaining: 2.63s\n",
            "414:\tlearn: 1.0000000\ttotal: 12.7s\tremaining: 2.6s\n",
            "415:\tlearn: 1.0000000\ttotal: 12.7s\tremaining: 2.57s\n",
            "416:\tlearn: 1.0000000\ttotal: 12.7s\tremaining: 2.54s\n",
            "417:\tlearn: 1.0000000\ttotal: 12.8s\tremaining: 2.5s\n",
            "418:\tlearn: 1.0000000\ttotal: 12.8s\tremaining: 2.48s\n",
            "419:\tlearn: 1.0000000\ttotal: 12.8s\tremaining: 2.44s\n",
            "420:\tlearn: 1.0000000\ttotal: 12.9s\tremaining: 2.41s\n",
            "421:\tlearn: 1.0000000\ttotal: 12.9s\tremaining: 2.38s\n",
            "422:\tlearn: 1.0000000\ttotal: 12.9s\tremaining: 2.35s\n",
            "423:\tlearn: 1.0000000\ttotal: 12.9s\tremaining: 2.32s\n",
            "424:\tlearn: 1.0000000\ttotal: 13s\tremaining: 2.29s\n",
            "425:\tlearn: 1.0000000\ttotal: 13s\tremaining: 2.26s\n",
            "426:\tlearn: 1.0000000\ttotal: 13s\tremaining: 2.23s\n",
            "427:\tlearn: 1.0000000\ttotal: 13.1s\tremaining: 2.2s\n",
            "428:\tlearn: 1.0000000\ttotal: 13.1s\tremaining: 2.17s\n",
            "429:\tlearn: 1.0000000\ttotal: 13.1s\tremaining: 2.13s\n",
            "430:\tlearn: 1.0000000\ttotal: 13.1s\tremaining: 2.1s\n",
            "431:\tlearn: 1.0000000\ttotal: 13.2s\tremaining: 2.07s\n",
            "432:\tlearn: 1.0000000\ttotal: 13.2s\tremaining: 2.04s\n",
            "433:\tlearn: 1.0000000\ttotal: 13.2s\tremaining: 2.01s\n",
            "434:\tlearn: 1.0000000\ttotal: 13.3s\tremaining: 1.98s\n",
            "435:\tlearn: 1.0000000\ttotal: 13.3s\tremaining: 1.95s\n",
            "436:\tlearn: 1.0000000\ttotal: 13.3s\tremaining: 1.92s\n",
            "437:\tlearn: 1.0000000\ttotal: 13.3s\tremaining: 1.89s\n",
            "438:\tlearn: 1.0000000\ttotal: 13.4s\tremaining: 1.86s\n",
            "439:\tlearn: 1.0000000\ttotal: 13.4s\tremaining: 1.83s\n",
            "440:\tlearn: 1.0000000\ttotal: 13.4s\tremaining: 1.8s\n",
            "441:\tlearn: 1.0000000\ttotal: 13.5s\tremaining: 1.77s\n",
            "442:\tlearn: 1.0000000\ttotal: 13.5s\tremaining: 1.74s\n",
            "443:\tlearn: 1.0000000\ttotal: 13.5s\tremaining: 1.71s\n",
            "444:\tlearn: 1.0000000\ttotal: 13.5s\tremaining: 1.67s\n",
            "445:\tlearn: 1.0000000\ttotal: 13.6s\tremaining: 1.64s\n",
            "446:\tlearn: 1.0000000\ttotal: 13.6s\tremaining: 1.61s\n",
            "447:\tlearn: 1.0000000\ttotal: 13.6s\tremaining: 1.58s\n",
            "448:\tlearn: 1.0000000\ttotal: 13.7s\tremaining: 1.55s\n",
            "449:\tlearn: 1.0000000\ttotal: 13.7s\tremaining: 1.52s\n",
            "450:\tlearn: 1.0000000\ttotal: 13.7s\tremaining: 1.49s\n",
            "451:\tlearn: 1.0000000\ttotal: 13.7s\tremaining: 1.46s\n",
            "452:\tlearn: 1.0000000\ttotal: 13.8s\tremaining: 1.43s\n",
            "453:\tlearn: 1.0000000\ttotal: 13.8s\tremaining: 1.4s\n",
            "454:\tlearn: 1.0000000\ttotal: 13.8s\tremaining: 1.37s\n",
            "455:\tlearn: 1.0000000\ttotal: 13.8s\tremaining: 1.34s\n",
            "456:\tlearn: 1.0000000\ttotal: 13.9s\tremaining: 1.3s\n",
            "457:\tlearn: 1.0000000\ttotal: 13.9s\tremaining: 1.27s\n",
            "458:\tlearn: 1.0000000\ttotal: 13.9s\tremaining: 1.24s\n",
            "459:\tlearn: 1.0000000\ttotal: 14s\tremaining: 1.21s\n",
            "460:\tlearn: 1.0000000\ttotal: 14s\tremaining: 1.18s\n",
            "461:\tlearn: 1.0000000\ttotal: 14s\tremaining: 1.15s\n",
            "462:\tlearn: 1.0000000\ttotal: 14s\tremaining: 1.12s\n",
            "463:\tlearn: 1.0000000\ttotal: 14.1s\tremaining: 1.09s\n",
            "464:\tlearn: 1.0000000\ttotal: 14.1s\tremaining: 1.06s\n",
            "465:\tlearn: 1.0000000\ttotal: 14.1s\tremaining: 1.03s\n",
            "466:\tlearn: 1.0000000\ttotal: 14.2s\tremaining: 1000ms\n",
            "467:\tlearn: 1.0000000\ttotal: 14.2s\tremaining: 970ms\n",
            "468:\tlearn: 1.0000000\ttotal: 14.2s\tremaining: 939ms\n",
            "469:\tlearn: 1.0000000\ttotal: 14.2s\tremaining: 909ms\n",
            "470:\tlearn: 1.0000000\ttotal: 14.3s\tremaining: 878ms\n",
            "471:\tlearn: 1.0000000\ttotal: 14.3s\tremaining: 847ms\n",
            "472:\tlearn: 1.0000000\ttotal: 14.3s\tremaining: 817ms\n",
            "473:\tlearn: 1.0000000\ttotal: 14.3s\tremaining: 787ms\n",
            "474:\tlearn: 1.0000000\ttotal: 14.4s\tremaining: 756ms\n",
            "475:\tlearn: 1.0000000\ttotal: 14.4s\tremaining: 726ms\n",
            "476:\tlearn: 1.0000000\ttotal: 14.4s\tremaining: 696ms\n",
            "477:\tlearn: 1.0000000\ttotal: 14.5s\tremaining: 666ms\n",
            "478:\tlearn: 1.0000000\ttotal: 14.5s\tremaining: 636ms\n",
            "479:\tlearn: 1.0000000\ttotal: 14.5s\tremaining: 605ms\n",
            "480:\tlearn: 1.0000000\ttotal: 14.5s\tremaining: 575ms\n",
            "481:\tlearn: 1.0000000\ttotal: 14.6s\tremaining: 544ms\n",
            "482:\tlearn: 1.0000000\ttotal: 14.6s\tremaining: 514ms\n",
            "483:\tlearn: 1.0000000\ttotal: 14.6s\tremaining: 484ms\n",
            "484:\tlearn: 1.0000000\ttotal: 14.7s\tremaining: 453ms\n",
            "485:\tlearn: 1.0000000\ttotal: 14.7s\tremaining: 423ms\n",
            "486:\tlearn: 1.0000000\ttotal: 14.7s\tremaining: 393ms\n",
            "487:\tlearn: 1.0000000\ttotal: 14.7s\tremaining: 362ms\n",
            "488:\tlearn: 1.0000000\ttotal: 14.8s\tremaining: 332ms\n",
            "489:\tlearn: 1.0000000\ttotal: 14.8s\tremaining: 302ms\n",
            "490:\tlearn: 1.0000000\ttotal: 14.8s\tremaining: 272ms\n",
            "491:\tlearn: 1.0000000\ttotal: 14.8s\tremaining: 241ms\n",
            "492:\tlearn: 1.0000000\ttotal: 14.9s\tremaining: 211ms\n",
            "493:\tlearn: 1.0000000\ttotal: 14.9s\tremaining: 181ms\n",
            "494:\tlearn: 1.0000000\ttotal: 14.9s\tremaining: 151ms\n",
            "495:\tlearn: 1.0000000\ttotal: 15s\tremaining: 121ms\n",
            "496:\tlearn: 1.0000000\ttotal: 15s\tremaining: 90.4ms\n",
            "497:\tlearn: 1.0000000\ttotal: 15s\tremaining: 60.3ms\n",
            "498:\tlearn: 1.0000000\ttotal: 15s\tremaining: 30.1ms\n",
            "499:\tlearn: 1.0000000\ttotal: 15.1s\tremaining: 0us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "nijMTzTbo2a3",
        "outputId": "c5bcd0d2-ea7a-46d7-d1f0-e7ca3acfa451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8dbf2ba5d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obsevation\n",
        "* Final F1-Score we get from our custom stacker is \\~ 0.78 whereas the hper-parameter tuned CatBoost gave the highest F1-Score of \\~ 0.80"
      ],
      "metadata": {
        "id": "jEsz4GMytpB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finally training the Catboost model and saving it for productionization.\n",
        "Since CatBoost model gave the highest score on metric, we'll use that."
      ],
      "metadata": {
        "id": "wUuyF0_3tk6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = {'min_data_in_leaf': 50, 'depth': 10, 'od_wait': 10, 'l2_leaf_reg': 3, 'iterations': 500, 'subsample': 0.5, 'rsm': 0.3, 'learning_rate': 0.1,\n",
        "                             'loss_function': 'Logloss','random_state':42,'eval_metric':'F1','custom_metric':'F1','one_hot_max_size':3}\n",
        "cat_features = X_train_cb.columns.values\n",
        "model = CatBoostClassifier(verbose=False,cat_features=cat_features,**best_params)\n",
        "# training\n",
        "model.fit(X_train_cb,y_train.values.ravel())\n",
        "# saving\n",
        "model.save_model(\"Final_cb\",format=\"cbm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7rea80wxT08",
        "outputId": "4018c383-f539-4a8a-83ab-c3930c6bb63b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7fa9995ea390>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### END"
      ],
      "metadata": {
        "id": "LOj6BpBBtlG8"
      }
    }
  ]
}