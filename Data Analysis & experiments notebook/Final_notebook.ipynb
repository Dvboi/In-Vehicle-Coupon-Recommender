{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "P98l7dqWTcYi"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Requirements"
      ],
      "metadata": {
        "id": "vTwjUJwcSLn5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n7BP4tHMyY4"
      },
      "outputs": [],
      "source": [
        "!pip install catboost\n",
        "from sklearn import metrics\n",
        "from catboost import CatBoostClassifier\n",
        "import pandas as pd\n",
        "import numpy as np "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions for data-preprocessing"
      ],
      "metadata": {
        "id": "rEIfKB51R1rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CatBoostClassifier().load_model(\"/content/drive/MyDrive/Datasets/Case-Study-1/Final_cb\")\n",
        "\n",
        "\n",
        "def custom_where(ele):\n",
        "    '''\n",
        "    Helper function to combine 3 redundant columns into 1 using simple if-else\n",
        "    Code is copied from our EDA notebook directly\n",
        "    '''\n",
        "\n",
        "    x,y,z = list(map(str,ele))\n",
        "    if x == '1':\n",
        "        if y=='1':\n",
        "            if z=='1':\n",
        "                return 'within 25mins'\n",
        "            else:\n",
        "                return 'within 15mins'\n",
        "        else:\n",
        "            return 'within 5mins'\n",
        "\n",
        "\n",
        "def mis_val_imputer(cols_to_impute,df):\n",
        "    ''' Impute missing values with most frequent category \n",
        "         Code is copied from our EDA notebook directly\n",
        "    '''\n",
        "    mis_val_imputewith_trainMode = {'Bar': 'never',\n",
        "                    'CarryAway': '1~3',\n",
        "                    'CoffeeHouse': 'less1',\n",
        "                    'Restaurant20To50': 'less1',\n",
        "                    'RestaurantLessThan20': '1~3'\n",
        "                    }\n",
        "    for col in cols_to_impute:\n",
        "        most_frequent_val = mis_val_imputewith_trainMode[col]\n",
        "        df.loc[:,col].fillna(most_frequent_val,inplace=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "def full_df_preprocessing(test_data):\n",
        "    '''\n",
        "    Whole test data chunk will be preprocessed here.\n",
        "    Code is copied from our EDA notebook directly\n",
        "    '''\n",
        "    df = test_data.copy()\n",
        "\n",
        "    # simple script to change values in a few columns\n",
        "    cols_that_need_wrangling = ['time','temperature', 'Bar',  'CoffeeHouse',  'CarryAway', 'RestaurantLessThan20','Restaurant20To50']\n",
        "\n",
        "    d_time = {\n",
        "        '7AM':'Morning',\n",
        "        '10AM':'Morning',\n",
        "        '2PM':'Evening',\n",
        "        '6PM':'Evening',\n",
        "        '10PM':'Night'\n",
        "    }\n",
        "    d_temp = {\n",
        "        55:'Low',\n",
        "        80:'High', \n",
        "        30:'Medium'\n",
        "    }\n",
        "    d = {\n",
        "        'less1':'Atmost 1', \n",
        "        '1~3':'1 to 3',\n",
        "        'gt8':'Greater than 8' , \n",
        "        '4~8':'4 to 8',\n",
        "        'never':'never'\n",
        "    }\n",
        "\n",
        "    mapping = [d_time,d_temp] + [d]*5\n",
        "\n",
        "    for column,d in zip(cols_that_need_wrangling,mapping):\n",
        "        df[column] = df[column].map(d)\n",
        "\n",
        "    df.expiration.replace({'1d':'24h'},inplace=True)\n",
        "\n",
        "    df['driving_distance'] = df[['toCoupon_GEQ5min','toCoupon_GEQ15min','toCoupon_GEQ25min']].apply(custom_where,axis=1,raw=True)\n",
        "    df.drop(['toCoupon_GEQ5min','toCoupon_GEQ15min','toCoupon_GEQ25min','direction_same','car'],axis=1,inplace=True)\n",
        "\n",
        "    possible_null_cols = ['Bar','CoffeeHouse','CarryAway','RestaurantLessThan20','Restaurant20To50']\n",
        "    df = mis_val_imputer(possible_null_cols,df)\n",
        "\n",
        "    return df.astype(str)"
      ],
      "metadata": {
        "id": "bawmDzxz2zua"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Functions"
      ],
      "metadata": {
        "id": "q_sA3tzzSBFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def final_fun_1(data_point,already_preprocessed=False):\n",
        "\n",
        "    ''' Receive a single data-point and make prediction \n",
        "        Please make sure 'data_point' is an array OR list\n",
        "    ''' \n",
        "    if not already_preprocessed:\n",
        "        # preprocessing\n",
        "\n",
        "        data_point = list(data_point)\n",
        "        # drop car,direc_same cols\n",
        "        data_point.pop(-2)\n",
        "        data_point.pop(-10)\n",
        "\n",
        "        # missing_val_imputer and remapping the values\n",
        "        d_mode_from_train = {\n",
        "            -5:'less1',\n",
        "            -6:'1~3',\n",
        "            -7:'1~3',\n",
        "            -8:'less1',\n",
        "            -9:'never'\n",
        "        }\n",
        "        coupon_freq_mapper = {\n",
        "        'less1':'Atmost 1', \n",
        "        '1~3':'1 to 3',\n",
        "        'gt8':'Greater than 8' , \n",
        "        '4~8':'4 to 8',\n",
        "        'never':'never'\n",
        "        }\n",
        "        # -5 to -10 cols are the respective indices from back\n",
        "        for idx in range(-5,-10,-1):\n",
        "            if data_point[idx]=='nan' or type(data_point[idx])==float:\n",
        "                if np.isnan(data_point[idx])==True:\n",
        "                    data_point[idx] = d_mode_from_train[idx]\n",
        "            data_point[idx] = coupon_freq_mapper[data_point[idx]]\n",
        "        \n",
        "\n",
        "        d_time = {\n",
        "        '7AM':'Morning',\n",
        "        '10AM':'Morning',\n",
        "        '2PM':'Evening',\n",
        "        '6PM':'Evening',\n",
        "        '10PM':'Night'\n",
        "        }\n",
        "        d_temp = {\n",
        "            55:'Low',\n",
        "            80:'High', \n",
        "            30:'Medium'\n",
        "        }\n",
        "        d_expiration = {'1d':'24h',\n",
        "                        '2h':'2h'}\n",
        "\n",
        "        data_point[3] = d_temp[data_point[3]]\n",
        "        data_point[4] = d_time[data_point[4]]\n",
        "        data_point[6] = d_expiration[data_point[6]]\n",
        "\n",
        "        # combine cols \n",
        "            # create a new column\n",
        "        driving_distance_colvalue = custom_where(data_point[-4:-1])\n",
        "            # drop 5,15,25-mins distance cols as they'be been combined above\n",
        "        del data_point[-4:-1]\n",
        "            # append the new column to data_point\n",
        "        data_point.append(driving_distance_colvalue)\n",
        "\n",
        "        # Finally convert point to str type\n",
        "        data_point = list(map(str,data_point))\n",
        "\n",
        "    # send the data point to model\n",
        "    y_pred = model.predict(data_point)\n",
        "    return y_pred\n",
        "\n",
        "def final_fun_2(test_data,y_test,already_preprocessed=False):\n",
        "\n",
        "    ''' \n",
        "    This function takes several data points as input and returns the evaluation metric\n",
        "    Please make sure that test_data is a dataframe\n",
        "    '''\n",
        "    if not already_preprocessed:\n",
        "        # Preprocessing\n",
        "        test_data = full_df_preprocessing(test_data)\n",
        "        # rearrange cols in a way that model was trained on\n",
        "        test_data = test_data[model.feature_names_]\n",
        "\n",
        "    # prediction\n",
        "    y_pred = model.predict(test_data)\n",
        "    y_pred_proba = model.predict_proba(test_data)[:,1]\n",
        "\n",
        "    # evaluation\n",
        "    f1 = metrics.f1_score(y_test.astype(int),y_pred)\n",
        "    auc = metrics.roc_auc_score(y_test.astype(int),y_pred_proba)\n",
        "\n",
        "    return f1,auc\n",
        "\n"
      ],
      "metadata": {
        "id": "Pdp1OSqeMzFK"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For personal testing"
      ],
      "metadata": {
        "id": "P98l7dqWTcYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # unpreprocessed data / RAW data / leakaged-data (AS MODEL IS TRAINED ON SOME OF THESE POINTS)\n",
        "# data = pd.read_csv('/content/drive/MyDrive/Datasets/Case-Study-1/in-vehicle-coupon-recommendation.csv')\n",
        "# Y = data.Y\n",
        "# data.drop(\"Y\",axis=1,inplace=True)\n",
        "# print(\"Prediction:\",final_fun_1(data.iloc[56,:]),\"Observed value:\",Y[56])\n",
        "# print(\"Metrics on all datapoints\",final_fun_2(data,Y))\n",
        "\n",
        "# # preprocessed data / unseen data\n",
        "# X_train = pd.read_csv('/content/drive/MyDrive/temporary_datasets/X_train_catboost.csv')\n",
        "# y_train = pd.read_csv('/content/drive/MyDrive/temporary_datasets/y_train.csv')\n",
        "\n",
        "# X_test = pd.read_csv('/content/drive/MyDrive/temporary_datasets/X_test_catboost.csv')\n",
        "# y_test = pd.read_csv('/content/drive/MyDrive/temporary_datasets/y_test.csv')\n",
        "\n",
        "# print(\"Prediction:\",final_fun_1(X_test.iloc[56,:],already_preprocessed=True),\"Observed value:\",y_test.iloc[56].values)\n",
        "# print(\"Metrics on unseen datapoints\",final_fun_2(X_test,y_test,already_preprocessed=True))"
      ],
      "metadata": {
        "id": "hWNX56NaVWKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## END"
      ],
      "metadata": {
        "id": "DxAYT-eqPmm_"
      }
    }
  ]
}